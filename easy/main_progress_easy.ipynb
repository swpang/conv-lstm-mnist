{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Environment Setting\n",
    "Google drive mount (for Colab users) and package importing.\n",
    "You can optionally install and import torchensemble package for ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random  \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## (Optional) Sample Visualization\n",
    "You can see actual sample images and sorted class indices. Additional matplotlib package is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Just for reference: see actual samples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alphabet = {\n",
    "        'A(a)' : '0', 'B(b)' : '1', 'C(c)' : '2', 'D(d)' : '3', 'E(e)' : '4', 'F(f)' : '5', \n",
    "        'G(g)' : '6', 'H(h)' : '7', 'I(i)' : '8', 'J(j)' : '9', 'K(k)' : '10','L(l)' : '11', \n",
    "        'M(m)' : '12', 'N(n)' : '13', 'O(o)' : '14', 'P(p)' : '15', 'Q(q)' : '16', 'R(r)' : '17', \n",
    "        'S(s)' : '18', 'T(t)' : '19', 'U(u)' : '20', 'V(v)' : '21', 'W(w)' : '22', 'X(x)' : '23', \n",
    "        'Y(y)' : '24', 'Z(z)' : '25'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Just for reference: see actual samples\n",
    "\n",
    "load_sample = np.load('./sample_data.npy', allow_pickle=True).item()\n",
    "# load_sample = np.load('/content/drive/MyDrive/final_proj_colab/emnist_progress_easy_data/sample_data.npy', allow_pickle=True).item()\n",
    "sample_data, sample_label = load_sample['train_data'], load_sample['train_label']\n",
    "print(len(sample_data))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(len(sample_data),len(sample_data)))\n",
    "for i in range(len(sample_data)):\n",
    "    plt.subplot(1, len(sample_data), i+1)\n",
    "    ax = plt.gca()\n",
    "    ax.axes.xaxis.set_ticklabels([])\n",
    "    ax.axes.yaxis.set_ticklabels([])\n",
    "    plt.imshow(sample_data[i], cmap='gray')\n",
    "    \n",
    "plt.show()\n",
    "print(\"progress label: \", end=' ')\n",
    "label_str = '('\n",
    "\n",
    "for i in range(len(sample_label)):\n",
    "    print(int(sample_label[i]), end=' ')\n",
    "    label_str += \" \" + list(alphabet.keys())[int(sample_label[i])]\n",
    "label_str += \" )\"\n",
    "print()\n",
    "print(label_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use 0th GPU for training\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fix random seed to increase reproducibility\n",
    "# NOTE: Do not modify here!\n",
    "\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "%env CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "\n",
    "def seed_worker(worker_seed):\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "# you can modify this\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: you can modify mean and std for normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: modify path for your setting\n",
    "\n",
    "from data_utils import Mydataset, collate_fn\n",
    "\n",
    "train_path = './train'\n",
    "valid_path = './valid'\n",
    "# train_path = '/content/drive/MyDrive/final_proj_colab/emnist_progress_easy_data/train'\n",
    "# valid_path = '/content/drive/MyDrive/final_proj_colab/emnist_progress_easy_data/valid'\n",
    "\n",
    "train_ds = Mydataset(train_path, transform=transform, train=True)\n",
    "valid_ds = Mydataset(valid_path, transform=transform, train=False)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "valid_dl= DataLoader(valid_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, model_optim, loss_func, max_epoch, train_dl, valid_dl, \n",
    "          load_path=None, save_path='./model.pt'):\n",
    "    ##############################################################################\n",
    "    #                          IMPLEMENT YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    # Load your states\n",
    "    loaded_epoch = 0\n",
    "    loaded_best_acc = -1\n",
    "    if load_path is not None:\n",
    "        state = torch.load(load_path)\n",
    "        model.load_state_dict(state[\"model\"])\n",
    "        model_optim.load_state_dict(state[\"optimizer\"])\n",
    "        loaded_epoch = state[\"epoch\"]\n",
    "        loaded_best_acc = state[\"best_acc\"]\n",
    "        # ...\n",
    "    start_time = time.time()\n",
    "        \n",
    "    ##############################################################################\n",
    "    #                          END OF YOUR CODE                                  #\n",
    "    ##############################################################################\n",
    "    \n",
    "    best_valid_accuracy = 0 if loaded_best_acc == -1 else loaded_best_acc\n",
    "\n",
    "    for epoch in np.array(list(range(max_epoch - loaded_epoch))) + loaded_epoch:\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        model.train()\n",
    "        for step, sample in enumerate(train_dl):\n",
    "            img, label = sample\n",
    "\n",
    "            model_optim.zero_grad()\n",
    "            outputs = model((img, label))\n",
    "            \n",
    "            ##############################################################################\n",
    "            #                          IMPLEMENT YOUR CODE                               #\n",
    "            ##############################################################################\n",
    "            # Problem 4: implement optimization part\n",
    "\n",
    "            loss = loss_func(outputs, label)\n",
    "            loss.backward()\n",
    "            model_optim.step()\n",
    "            \n",
    "            ##############################################################################\n",
    "            #                          END OF YOUR CODE                                  #\n",
    "            ##############################################################################\n",
    "            \n",
    "            # you can modify below train evaluation code\n",
    "            n_samples += len(label)\n",
    "            for j in range(len(label)):\n",
    "                n_correct += (outputs[j].argmax(-1)[-1] == label[j][-1].cuda()).sum().item()\n",
    "            \n",
    "            if (step + 1) % print_interval == 0:\n",
    "                print('epoch:', epoch + 1, 'step:', step + 1, 'loss:', loss.item(), 'accuracy:', 100 * (n_correct / n_samples))\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print('elapsed time : %d h %d m %d s' % (elapsed_time / 3600, (elapsed_time % 3600) / 60, (elapsed_time % 60)))            \n",
    "                \n",
    "        # you can modify evaluation code\n",
    "                \n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for step, sample in enumerate(valid_dl):\n",
    "                img, label = sample            \n",
    "                outputs = model(img)\n",
    "                n_samples += len(label)                \n",
    "                for j in range(len(label)):\n",
    "                    n_correct += (outputs[j].argmax(-1)[-1] == label[j][-1].cuda()).sum().item()\n",
    "            \n",
    "            valid_accuracy = 100 * (n_correct/n_samples)\n",
    "            if valid_accuracy > best_valid_accuracy:\n",
    "                print(\"New best valid accuracy, saving model\")\n",
    "                ##############################################################################\n",
    "                #                          IMPLEMENT YOUR CODE                               #\n",
    "                ##############################################################################\n",
    "                # Save your states (optional)\n",
    "                state = {\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"optimizer\": model_optim.state_dict(),\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"best_acc\": best_valid_accuracy,\n",
    "                    # ...\n",
    "                }\n",
    "                ##############################################################################\n",
    "                #                          END OF YOUR CODE                                  #\n",
    "                ##############################################################################\n",
    "                torch.save(state, save_path)\n",
    "                best_valid_accuracy = valid_accuracy\n",
    "            print('Valid epoch: %d, Valid accuracy: %.2f, Best valid accuracy: %.2f' % (epoch + 1, valid_accuracy, best_valid_accuracy))\n",
    "\n",
    "# you can modify evaluation code\n",
    "def eval(valid_dl, load_path):\n",
    "    state = torch.load(load_path)\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    ##############################################################################\n",
    "    #                          IMPLEMENT YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    # Problem 5: implement evaluation part\n",
    "    # you can simply copy or modify above evaluation code in train function\n",
    "    n_samples = 0\n",
    "    n_correct = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for step, sample in enumerate(valid_dl):\n",
    "            img, label = sample\n",
    "            outputs = model(img)\n",
    "            n_samples += len(label)\n",
    "            for j in range(len(label)):\n",
    "                n_correct += (outputs[j].argmax(-1)[-1] == label[j][-1].cuda()).sum().item()\n",
    "\n",
    "    ##############################################################################\n",
    "    #                          END OF YOUR CODE                                  #\n",
    "    ##############################################################################\n",
    "        \n",
    "    valid_accuracy = 100 * (n_correct/n_samples)\n",
    "    print('Valid accuracy: %.2f' % (valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# You can add or modify your ConvLSTM's hyperparameter (keys and values)\n",
    "kwargs = {\n",
    "    'cnn_input_dim': 1,\n",
    "    'cnn_hidden_size': 256,\n",
    "    'rnn_input_dim': 256,\n",
    "    'rnn_hidden_size': 32,\n",
    "    'rnn_num_layers': 2,\n",
    "    'rnn_dropout': 1\n",
    "}\n",
    "\n",
    "NUM_CLASSES = 26\n",
    "SEQUENCE_LENGTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for reload .py file without restart\n",
    "import models_easy\n",
    "import importlib\n",
    "\n",
    "importlib.reload(models_easy)\n",
    "\n",
    "from models_easy import ConvLSTM\n",
    "\n",
    "model = ConvLSTM(sequence_length=SEQUENCE_LENGTH, num_classes=NUM_CLASSES, **kwargs).cuda()\n",
    "print(model)\n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "model_optim = optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: you can modify hyperparameters\n",
    "\n",
    "print_interval = 15\n",
    "max_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "load_path = None\n",
    "train(model, model_optim, loss_func, max_epoch, train_dl, valid_dl, load_path=load_path, save_path='./model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load and evaluate model\n",
    "load_path = './model.pt'\n",
    "eval(valid_dl, load_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test code for grading by TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# you do not need to modify here\n",
    "from data_utils import Mydataset, collate_fn\n",
    "\n",
    "test_path = './data/emnist_progress_easy_data/test'\n",
    "test_ds = Mydataset(test_path, transform=transform, train=False)\n",
    "test_dl= DataLoader(test_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# please change the model name to your submission model name\n",
    "load_path = './model.pt'\n",
    "eval(test_dl, load_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}